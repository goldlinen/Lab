{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56f09127",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37aff323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['amit', 'eric', 'kevin', 'moxa', 'parneet', 'nico', 'xinyan']\n",
      "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "words = open('names.txt').read().splitlines()\n",
    "vocab = list(set(''.join(words)))\n",
    "vocab.sort()\n",
    "print(words[:7])\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d3e302d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "{'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26, '.': 0}\n"
     ]
    }
   ],
   "source": [
    "itos = {i+1:vocab[i] for i in range(len(vocab))}\n",
    "stoi = {vocab[i]:i+1 for i in range(len(vocab))}\n",
    "itos[0] = '.'\n",
    "stoi['.'] = 0\n",
    "\n",
    "print(itos)\n",
    "print(stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4964911d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the dataset\n",
    "def create_dataset(words, block_size = 3, do_print=False):\n",
    "    X, Y = [], []\n",
    "    for word in words:\n",
    "        context = [0] * block_size\n",
    "        for w in word + '.':\n",
    "            X.append(context)\n",
    "            Y.append(stoi[w])\n",
    "            context = context[1:] + [stoi[w]]\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    if do_print:\n",
    "        print(X.shape)\n",
    "        print(Y.shape)\n",
    "        for row in range(X.shape[0]):\n",
    "            xes = [itos[X[row][i].item()] for i in range(X.shape[1])]\n",
    "            y = itos[Y[row].item()]\n",
    "            print(f\"prediction for {''.join(xes)}: {y}\")\n",
    "    return X,Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a03ec73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([41, 3])\n",
      "torch.Size([41])\n",
      "prediction for ...: a\n",
      "prediction for ..a: m\n",
      "prediction for .am: i\n",
      "prediction for ami: t\n",
      "prediction for mit: .\n",
      "prediction for ...: e\n",
      "prediction for ..e: r\n",
      "prediction for .er: i\n",
      "prediction for eri: c\n",
      "prediction for ric: .\n",
      "prediction for ...: k\n",
      "prediction for ..k: e\n",
      "prediction for .ke: v\n",
      "prediction for kev: i\n",
      "prediction for evi: n\n",
      "prediction for vin: .\n",
      "prediction for ...: m\n",
      "prediction for ..m: o\n",
      "prediction for .mo: x\n",
      "prediction for mox: a\n",
      "prediction for oxa: .\n",
      "prediction for ...: p\n",
      "prediction for ..p: a\n",
      "prediction for .pa: r\n",
      "prediction for par: n\n",
      "prediction for arn: e\n",
      "prediction for rne: e\n",
      "prediction for nee: t\n",
      "prediction for eet: .\n",
      "prediction for ...: n\n",
      "prediction for ..n: i\n",
      "prediction for .ni: c\n",
      "prediction for nic: o\n",
      "prediction for ico: .\n",
      "prediction for ...: x\n",
      "prediction for ..x: i\n",
      "prediction for .xi: n\n",
      "prediction for xin: y\n",
      "prediction for iny: a\n",
      "prediction for nya: n\n",
      "prediction for yan: .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  0,  0],\n",
       "         [ 0,  0,  1],\n",
       "         [ 0,  1, 13],\n",
       "         [ 1, 13,  9],\n",
       "         [13,  9, 20],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  5],\n",
       "         [ 0,  5, 18],\n",
       "         [ 5, 18,  9],\n",
       "         [18,  9,  3],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0, 11],\n",
       "         [ 0, 11,  5],\n",
       "         [11,  5, 22],\n",
       "         [ 5, 22,  9],\n",
       "         [22,  9, 14],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0, 13],\n",
       "         [ 0, 13, 15],\n",
       "         [13, 15, 24],\n",
       "         [15, 24,  1],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0, 16],\n",
       "         [ 0, 16,  1],\n",
       "         [16,  1, 18],\n",
       "         [ 1, 18, 14],\n",
       "         [18, 14,  5],\n",
       "         [14,  5,  5],\n",
       "         [ 5,  5, 20],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0, 14],\n",
       "         [ 0, 14,  9],\n",
       "         [14,  9,  3],\n",
       "         [ 9,  3, 15],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0, 24],\n",
       "         [ 0, 24,  9],\n",
       "         [24,  9, 14],\n",
       "         [ 9, 14, 25],\n",
       "         [14, 25,  1],\n",
       "         [25,  1, 14]]),\n",
       " tensor([ 1, 13,  9, 20,  0,  5, 18,  9,  3,  0, 11,  5, 22,  9, 14,  0, 13, 15,\n",
       "         24,  1,  0, 16,  1, 18, 14,  5,  5, 20,  0, 14,  9,  3, 15,  0, 24,  9,\n",
       "         14, 25,  1, 14,  0]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_dataset(words[:7], do_print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03f413fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num params: 6881\n"
     ]
    }
   ],
   "source": [
    "# for purpose of demo, don't bother with train, val, test\n",
    "block_size = 3\n",
    "vocab_size = len(vocab) + 1\n",
    "emb_size = 2 # how many embeddings do we want\n",
    "num_hidden = 200 # how big of a hidden layer\n",
    "\n",
    "X, Y = create_dataset(words)\n",
    "C = torch.randn(vocab_size, emb_size, requires_grad=True)\n",
    "W1 = torch.randn(emb_size * block_size, num_hidden, requires_grad=True)\n",
    "b1 = torch.randn(num_hidden, requires_grad=True)\n",
    "W2 = torch.randn(num_hidden, vocab_size, requires_grad=True)\n",
    "b2 = torch.randn(vocab_size, requires_grad=True)\n",
    "\n",
    "params = [C, W1, b1, W2, b2]\n",
    "acc = 0\n",
    "for p in params:\n",
    "    acc = acc + p.numel()\n",
    "\n",
    "print(f\"num params: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18a2623d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([228187, 3])\n",
      "tensor([0, 0, 0])\n",
      "torch.Size([228187])\n",
      "tensor(1)\n",
      "torch.Size([192])\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(X[0])\n",
    "print(Y.shape)\n",
    "print(Y[0])\n",
    "\n",
    "ix = torch.randint(0, X.shape[0], (32,))\n",
    "embs = C[X[ix]]\n",
    "embs = embs.view(-1)\n",
    "print(embs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcf5ca79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(X, Y, batch_size=32, num_iters=10000):\n",
    "    lossi = []\n",
    "    for i in range(num_iters):\n",
    "        ix = torch.randint(0, X.shape[0], (batch_size,))\n",
    "        embs = C[X[ix]]\n",
    "        preact = embs.view(batch_size, -1) @ W1 + b1\n",
    "        h = torch.tanh(preact)\n",
    "        logits = h @ W2 + b2\n",
    "        loss = F.cross_entropy(logits, Y[ix])\n",
    "        lossi.append(loss.item())\n",
    "        if i % 1000 == 0:\n",
    "            print(loss.item())\n",
    "\n",
    "        # backprop\n",
    "        for p in params:\n",
    "            p.grad = None\n",
    "        loss.backward()\n",
    "\n",
    "        # learn\n",
    "        for p in params:\n",
    "            p.data = p.grad *(-0.1) + p.data\n",
    "    return lossi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4a686dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.121305465698242\n",
      "3.3761239051818848\n",
      "3.3347816467285156\n",
      "2.8541080951690674\n",
      "2.5937540531158447\n",
      "2.5225226879119873\n",
      "2.5181028842926025\n",
      "2.710533380508423\n",
      "2.5936741828918457\n",
      "2.8997180461883545\n"
     ]
    }
   ],
   "source": [
    "lossi = train(X, Y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10702147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now generate and show the power of the MLP\n",
    "\n",
    "def generate_names(count, should_print = False):\n",
    "    for i in range(count):\n",
    "        context = [0] * block_size\n",
    "        newname = []\n",
    "        while True:\n",
    "            embs = C[context]\n",
    "            preact = embs.view(1, -1) @ W1 + b1\n",
    "            h = torch.tanh(preact)\n",
    "            logits = h @ W2 + b2\n",
    "            counts = logits.exp()\n",
    "            probs = counts / counts.sum(1, keepdim=True)\n",
    "            if should_print:\n",
    "                top5 = torch.topk(probs, 5)\n",
    "                # print(top5)\n",
    "                top5vals = [i.item() for i in top5.values.squeeze()]\n",
    "                top5lets = [itos[i.item()] for i in top5.indices.squeeze()]\n",
    "                top5z = zip(top5vals, top5lets)\n",
    "                for e in top5z:\n",
    "                    print(e)\n",
    "                print(f\"------ top prob {top5lets[0]} ------\")\n",
    "\n",
    "            # we don't necessarily choose the top probability, we sample from the distribution\n",
    "            nci = torch.multinomial(probs, 1, True).item()\n",
    "            context = context[1:] + [nci]\n",
    "            newname.append(itos[nci])\n",
    "            if nci == 0:\n",
    "                break\n",
    "        print(''.join(newname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55fc1501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.1292458474636078, 'k')\n",
      "(0.0983208417892456, 'j')\n",
      "(0.08199865370988846, 'e')\n",
      "(0.07372533529996872, 'z')\n",
      "(0.06550216674804688, 'd')\n",
      "------ top prob k ------\n",
      "(0.4711335003376007, 'e')\n",
      "(0.2040032297372818, 'a')\n",
      "(0.10118529945611954, 'i')\n",
      "(0.0784405916929245, 'o')\n",
      "(0.05000215768814087, 'y')\n",
      "------ top prob e ------\n",
      "(0.1711379885673523, 'l')\n",
      "(0.15458017587661743, 'n')\n",
      "(0.1257237046957016, 's')\n",
      "(0.11900298297405243, 'e')\n",
      "(0.05749349296092987, 'i')\n",
      "------ top prob l ------\n",
      "(0.32772204279899597, '.')\n",
      "(0.1511790007352829, 'l')\n",
      "(0.1402026116847992, 'n')\n",
      "(0.06645282357931137, 's')\n",
      "(0.06362863630056381, 'a')\n",
      "------ top prob . ------\n",
      "nae.\n"
     ]
    }
   ],
   "source": [
    "generate_names(1, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d9237a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
